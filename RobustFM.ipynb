{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T04:38:51.009946Z",
     "start_time": "2017-06-23T04:38:50.993434Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "import warnings\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "mem = Memory('./mycache')\n",
    "\n",
    "# The Memory class defines a context for lazy evaluation of function, by storing the results to the disk, \n",
    "# and not rerunning the function twice for the same arguments.\n",
    "# It works by explicitly saving the output to a file and it is designed to work with non-hashable and potentially large input and output data types such as numpy arrays.\n",
    "@mem.cache\n",
    "def get_data(file_path):\n",
    "    data = load_svmlight_file(file_path)\n",
    "    return data\n",
    "\n",
    "# classification task\n",
    "# a1a\n",
    "a1a_train = 'data/a1a/a1a.train'\n",
    "a1a_test = 'data/a1a/a1a.test'\n",
    "# a8a\n",
    "a8a_train = 'data/a8a/a8a.train'\n",
    "a8a_test = 'data/a8a/a8a.test'\n",
    "#ijcnn\n",
    "ijcnn_train = 'data/ijcnn/ijcnn.train'\n",
    "ijcnn_test = 'data/ijcnn/ijcnn.test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T04:03:13.317220Z",
     "start_time": "2017-06-23T04:03:12.919458Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def fm(train_x, train_y, test_x, test_y, training_config):\n",
    "    # pack parameters\n",
    "    learning_rate = training_config['learning_rate'] if 'learning_rate' in training_config else 1e-2\n",
    "    reg = training_config['reg'] if 'reg' in training_config else 1e-4\n",
    "    factor = training_config['factor'] if 'factor' in training_config else 10\n",
    "    task = training_config['task_type'] if 'task_type' in training_config else 'regression'\n",
    "    \n",
    "    if task not in ['classification', 'regression']:\n",
    "        raise Exception('unsupported task type')\n",
    "    \n",
    "    epoch = training_config['epoch'] if 'epoch' in training_config else 10\n",
    "    verbose = training_config['verbose'] if 'verbose' in training_config else True\n",
    "    is_shuffle = training_config['shuffle'] if 'shuffle' in training_config else True\n",
    "    \n",
    "    seed = training_config['seed'] if 'seed' in training_config else 1\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    training_num, p = train_x.shape\n",
    "    test_num, p_test = test_x.shape\n",
    "    \n",
    "    if p != p_test:\n",
    "        warnings.warn ('different dimensions in test and train data')\n",
    "        p = max(p, p_test)\n",
    "        \n",
    "    # mandatory shuffle at the beginning\n",
    "    x_train, y_train = shuffle(train_x, train_y, random_state=seed)\n",
    "    \n",
    "    train_loss_epochwise = []\n",
    "    test_loss_epochwise = []\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        \n",
    "        # initialization\n",
    "        w0 = 0;\n",
    "        W = np.zeros([1,p])\n",
    "        V = 0.1*np.random.randn(p, factor)\n",
    "        \n",
    "        # if shuffle is true, do shuffle each epoch\n",
    "        if is_shuffle:\n",
    "            x_train, y_train = shuffle(train_x, train_y, random_state=seed)\n",
    "        \n",
    "        loss = 0\n",
    "        for j in range(training_num):\n",
    "            \n",
    "            x = x_train[j]\n",
    "            y = y_train[j]\n",
    "            nz_idx = np.nonzero(x)[1]\n",
    "            \n",
    "            x = x[np.nonzero(x)]\n",
    "            tmp = np.sum(np.multiply(np.matlib.repmat(x.T,1,factor),V[nz_idx,:]));\n",
    "            factor_part = np.sum(np.square(tmp)) - np.sum(np.multiply(np.matlib.repmat(np.square(x.T),1,factor),np.square(V[nz_idx,:])))/2\n",
    "            y_predict = (w0 + np.dot(W[:,nz_idx],x.T) + factor_part).item()\n",
    "            \n",
    "            if task == 'classification':\n",
    "                err = 1/(1+np.exp(-y_predict*y))\n",
    "                loss += (-np.log(err))\n",
    "            \n",
    "            if task == 'regression':\n",
    "                err = y_predict - y\n",
    "                loss += err**2\n",
    "            \n",
    "            # update\n",
    "            if task == 'classification':\n",
    "                w0_ = learning_rate * (err - 1) * y + 2 * reg * w0\n",
    "                w0 -= w0_\n",
    "                \n",
    "                W_ = learning_rate * (err-1)*y*x + 2 * reg * W[:,nz_idx]\n",
    "                W[:,nz_idx] -= W_\n",
    "                \n",
    "                V_ = learning_rate * (err - 1) * y *\\\n",
    "                np.multiply(\n",
    "                    np.matlib.repmat(x.T,1,factor),(\n",
    "                        np.matlib.repmat(np.dot(x,V[nz_idx,:]),len(nz_idx),1)-\\\n",
    "                        np.multiply(np.matlib.repmat(x.T,1,factor),V[nz_idx,:])\n",
    "                    )\n",
    "                ) + 2 * reg * V[nz_idx,:]\n",
    "                V[nz_idx,:] -= V_\n",
    "            if task == 'regression':\n",
    "                w0_ = learning_rate * 2 * err + 2 * reg * w0\n",
    "                w0 -= w0_\n",
    "                \n",
    "                W_ = learning_rate * 2 * err * x + 2 * reg * W[:,nz_idx]\n",
    "                W[:,nz_idx] -= W_\n",
    "                \n",
    "                V_ = learning_rate * 2 * err *\\\n",
    "                np.multiply(\n",
    "                    np.matlib.repmat(x.T,1,factor),(\n",
    "                        np.matlib.repmat(np.dot(x,V[nz_idx,:]),len(nz_idx),1)-\\\n",
    "                        np.multiply(np.matlib.repmat(x.T,1,factor),V[nz_idx,:])\n",
    "                    )\n",
    "                ) + 2 * reg * V[nz_idx,:]\n",
    "                V[nz_idx,:] -= V_\n",
    "        \n",
    "        train_loss_epochwise.append(loss/training_num)\n",
    "        \n",
    "        if verbose:\n",
    "            print('epoch[%d]---train loss: %.4f\\t' % (i,loss/training_num))\n",
    "            \n",
    "        loss = 0   \n",
    "        # validation\n",
    "        for j in range(test_num):\n",
    "            x = test_x[j]\n",
    "            y = test_y[j]\n",
    "            nz_idx = np.nonzero(x)[1]\n",
    "            \n",
    "            x = x[np.nonzero(x)]\n",
    "            tmp = np.sum(np.multiply(np.matlib.repmat(x.T,1,factor),V[nz_idx,:]));\n",
    "            factor_part = np.sum(np.square(tmp)) - np.sum(np.multiply(np.matlib.repmat(np.square(x.T),1,factor),np.square(V[nz_idx,:])))/2\n",
    "            y_predict = (w0 + np.dot(W[:,nz_idx],x.T) + factor_part).item()\n",
    "            \n",
    "            if task == 'classification':\n",
    "                err = 1/(1+np.exp(-y_predict*y))\n",
    "                loss += (-np.log(err))\n",
    "            \n",
    "            if task == 'regression':\n",
    "                err = y_predict - y\n",
    "                loss += err**2\n",
    "                \n",
    "        test_loss_epochwise.append(loss/test_num)\n",
    "        \n",
    "        if verbose:\n",
    "            print('test loss: %.4f\\n' % (loss/test_num))\n",
    "        \n",
    "    return train_loss_epochwise, test_loss_epochwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-23T04:55:28.921417Z",
     "start_time": "2017-06-23T04:39:44.862576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__-F%3A-Github-Robust-FM-__ipython-input__.get_data...\n",
      "get_data('data/ijcnn/ijcnn.train')\n",
      "_________________________________________________________get_data - 0.8s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__-F%3A-Github-Robust-FM-__ipython-input__.get_data...\n",
      "get_data('data/ijcnn/ijcnn.test')\n",
      "_________________________________________________________get_data - 1.7s, 0.0min\n",
      "epoch[0]---train loss: 0.5387\t\n",
      "test loss: 0.4220\n",
      "\n",
      "epoch[1]---train loss: 0.5221\t\n",
      "test loss: 0.4168\n",
      "\n",
      "epoch[2]---train loss: 0.5104\t\n",
      "test loss: 0.3952\n",
      "\n",
      "epoch[3]---train loss: 0.5097\t\n",
      "test loss: 0.4001\n",
      "\n",
      "epoch[4]---train loss: 0.5402\t\n",
      "test loss: 0.4114\n",
      "\n",
      "epoch[5]---train loss: 0.5656\t\n",
      "test loss: 0.4501\n",
      "\n",
      "epoch[6]---train loss: 0.5072\t\n",
      "test loss: 0.3980\n",
      "\n",
      "epoch[7]---train loss: 0.5161\t\n",
      "test loss: 0.3998\n",
      "\n",
      "epoch[8]---train loss: 0.5233\t\n",
      "test loss: 0.4194\n",
      "\n",
      "epoch[9]---train loss: 0.5101\t\n",
      "test loss: 0.4043\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.53874261197698359,\n",
       "  0.52212617242787174,\n",
       "  0.51035116216647214,\n",
       "  0.50971187179941413,\n",
       "  0.5402288711132357,\n",
       "  0.56557451660732483,\n",
       "  0.50719337145674137,\n",
       "  0.51614400881132538,\n",
       "  0.52330734136409451,\n",
       "  0.51010196725309254],\n",
       " [0.42196492062644703,\n",
       "  0.41681232939166735,\n",
       "  0.39524568984388514,\n",
       "  0.40014059938253754,\n",
       "  0.41139868555174625,\n",
       "  0.45005807247123458,\n",
       "  0.39804388010211295,\n",
       "  0.39984408229531448,\n",
       "  0.41944901148156583,\n",
       "  0.40426564870054948])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = ijcnn_train\n",
    "test_data = ijcnn_test\n",
    "\n",
    "train_x, train_y = get_data(train_data)\n",
    "test_x, test_y = get_data(test_data)\n",
    "\n",
    "training_config = {\n",
    "    'learning_rate':1e-4,\n",
    "    'reg':0,\n",
    "    'task_type':'classification',\n",
    "    'factor': 10,\n",
    "    'verbose': True,\n",
    "    'epoch': 10,\n",
    "    'shuffle': False,\n",
    "    'seed': 2017\n",
    "}\n",
    "fm(train_x, train_y, test_x, test_y, training_config);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
