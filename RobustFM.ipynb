{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T15:42:00.998603Z",
     "start_time": "2017-06-20T15:42:00.975588Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "mem = Memory('./mycache')\n",
    "\n",
    "# The Memory class defines a context for lazy evaluation of function, by storing the results to the disk, \n",
    "# and not rerunning the function twice for the same arguments.\n",
    "# It works by explicitly saving the output to a file and it is designed to work with non-hashable and potentially large input and output data types such as numpy arrays.\n",
    "@mem.cache\n",
    "def get_data(file_path):\n",
    "    data = load_svmlight_file(file_path)\n",
    "    return data\n",
    "\n",
    "# classification task\n",
    "# a1a\n",
    "a1a_train = 'data/a1a/a1a.train'\n",
    "a1a_test = 'data/a1a/a1a.test'\n",
    "data = get_data(a1a_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T13:13:15.827762Z",
     "start_time": "2017-06-20T13:13:15.820757Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fm(train_x, train_y, test_x, training_config):\n",
    "    \n",
    "    # pack parameters\n",
    "    learning_rate = training_config['learning_rate'] if hasattr(training_config, 'learning_rate') else 1e-2\n",
    "    reg = training_config['reg'] if hasattr(training_config, 'reg') else 1e-4\n",
    "    factor = training_config['factor'] if hasattr(contraining_configfig, 'factor') else 10\n",
    "    task_type = training_config['task_type'] if hasattr(training_config, 'task_type') else 'regression'\n",
    "    \n",
    "    if task_type not in ['classfication', 'regression']:\n",
    "        raise Exception('unsupported task type')\n",
    "    \n",
    "    epoch = training_config['epoch'] if hasattr(training_config, 'epoch') else 10\n",
    "    verbose = training_config['verbose'] if hasattr(training_config, 'verbose') else True\n",
    "    is_shuffle = training_config['shuffle'] is hasattr(training_config, 'shuffle') else True\n",
    "    \n",
    "    seed = training_config['seed'] if hasattr(training_config, 'seed') else 1\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    training_num, p = train_x.shape\n",
    "    \n",
    "    # mandatory shuffle at the beginning\n",
    "    x_train, y_train = shuffle(train_x, train_y, random_state=seed)\n",
    "    \n",
    "    train_loss_epochwise = []\n",
    "    test_loss_epochwise = []\n",
    "    \n",
    "    for i in xrange(epoch):\n",
    "        \n",
    "        # initialization\n",
    "        w0 = 0;\n",
    "        W = np.zeros(1,p)\n",
    "        V = 0.1*np.random.randn(p, factor)\n",
    "        \n",
    "        # if shuffle is true, do shuffle each epoch\n",
    "        if is_shuffle:\n",
    "            x_train, y_train = shuffle(train_x, train_y, random_state=seed)\n",
    "        \n",
    "        for j in range(training_num):\n",
    "            # logloss for classfication\n",
    "            if task == \"classfication\":\n",
    "                \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
